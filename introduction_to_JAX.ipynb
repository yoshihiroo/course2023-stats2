{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2023-stats2/blob/main/introduction_to_JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bCTE9ku1vWN"
      },
      "source": [
        "# JAX+Flax入門\n",
        "\n",
        "* このnotebookは、以下のthe University of Amsterdamの講義資料を元に作成した。\n",
        " * Phillip Lippe, [Tutorial 2 (JAX): Introduction to JAX+Flax](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ISs7P_P1vWP"
      },
      "source": [
        "* JAXのPros\n",
        " * コードの見た目がNumPyとそっくり。\n",
        " * just-in-time (JIT) コンパイラでGPUやTPUのハードウェアとしての能力を最大限に利用できる。\n",
        " * コンパイル時にコードの最適化も行われる。\n",
        " * 一定の制約を満たせば、いったんコンパイルした効率の良いコードを、何度でも使いまわせる。\n",
        "\n",
        "* JAXのCons\n",
        " * JITコンパイラを使えるようなコードを書かなければならない。例えば・・・\n",
        " * **side-effectのある関数（namespaceの外側の関数に影響を与える関数）は扱えない。**\n",
        "   * cf. https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#jax-the-sharp-bits\n",
        " * このため、疑似乱数の扱いもやや煩雑となる。\n",
        " * **条件によって演算の対象となる配列やテンソルの形が変わる処理は扱えない。**（例：`y = x[x>3]`)\n",
        " \n",
        "* とはいえ、深層学習で使われる多くの計算は、JAXのJIT compilingの制約を満たす。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JAX+Flaxの入門として参考になるサイト\n",
        " * [JAX 101](https://jax.readthedocs.io/en/latest/jax-101/index.html)\n",
        " * [JAX - The Sharp Bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)\n",
        " * [Jax for the Impatient](https://flax.readthedocs.io/en/latest/notebooks/jax_for_the_impatient.html)\n"
      ],
      "metadata": {
        "id": "MxMhtUTB5Maa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Flax](https://flax.readthedocs.io/en/latest/) はJAXの深層学習ライブラリ。\n",
        " * 参考： [Flax Basics](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html)\n",
        "\n",
        "* [Optax](https://optax.readthedocs.io/en/latest/index.html) は深層学習でよく使われるoptimizerをJAXで実装したもの。"
      ],
      "metadata": {
        "id": "RF8WG_dp6Z2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JAXはPyTorchのDataLoaderやTensorFlowのTensorBoardと組み合わせて使える。\n",
        " * 深層学習モデルの定義や学習の部分だけ、JAXに置き換えればよい。\n"
      ],
      "metadata": {
        "id": "TaVFj_4S5b8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備\n",
        "* 最初に、ランタイムのタイプをGPUに設定してください。"
      ],
      "metadata": {
        "id": "jPam_loQ7T81"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G94NqIKK1vWQ"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np \n",
        "import time\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IYcmg8i1vWR"
      },
      "source": [
        "## アクセラレータ上のNumPyとしてのJAX\n",
        "\n",
        "* JAXの基本的なAPIは[NumPy](https://numpy.org/)とそっくり。\n",
        "* 名前も同じ (`jax.numpy`)。\n",
        "* というわけで、とりあえずはJAXをアクセラレータ上で走るNumPyとみなしてよい。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIkooaBU1vWR"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "print(\"Using jax\", jax.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8YQ9XQk1vWS"
      },
      "source": [
        "### JAXの配列"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 配列の作り方はNumPyとほとんど同じ。"
      ],
      "metadata": {
        "id": "QWkbEZfF8ZOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXolsg1i1vWT"
      },
      "outputs": [],
      "source": [
        "a = jnp.zeros((2, 5), dtype=jnp.float32)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asa70Xhl1vWT"
      },
      "outputs": [],
      "source": [
        "b = jnp.arange(6)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLjJj2nn1vWU"
      },
      "source": [
        "* だが、classは異なる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTPzXvsC1vWU"
      },
      "outputs": [],
      "source": [
        "b.__class__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYvjlsli1vWU"
      },
      "source": [
        "* `DeviceArray`型は、NumPyの`ndarray`とは異なり、CPU, GPU, TPUのいずれでも使える。\n",
        "* PyTorchのように、`.device()`で、どのデバイスにあるかを調べられる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHafNCa21vWU"
      },
      "outputs": [],
      "source": [
        "b.device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otiHUc-_1vWV"
      },
      "source": [
        "* このようにJAXでは配列がデフォルトでGPU上に作られる。\n",
        "* 配列のデバイスをCPUへ変えるには、`jax.device_get`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5pEBOoa1vWV"
      },
      "outputs": [],
      "source": [
        "b_cpu = jax.device_get(b)\n",
        "print(b_cpu.__class__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m5Rxqd21vWV"
      },
      "source": [
        "* CPU上に持ってきた配列は、NumPyの`ndarray`になる。\n",
        "* 逆に、NumPyの配列をアクセラレータに移動させるには、`jax.device_put`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCpckk2L1vWV"
      },
      "outputs": [],
      "source": [
        "b_gpu = jax.device_put(b_cpu)\n",
        "print(f'Device put: {b_gpu.__class__} on {b_gpu.device()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sagjplF1vWV"
      },
      "source": [
        "* CPUとGPUにある配列を混在させると、デフォルトで計算結果はGPUに置かれる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwZoiINN1vWW"
      },
      "outputs": [],
      "source": [
        "(b_cpu + b_gpu).device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNlwnH4z1vWW"
      },
      "source": [
        "* 利用可能なデバイス一覧を`jax.devices()`で取得できる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xzbi2Jq1vWW"
      },
      "outputs": [],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTmzWnjx1vWX"
      },
      "source": [
        "### JAXにおける擬似乱数\n",
        "\n",
        "* 計算機が生成する乱数は、本物の乱数ではなく、擬似乱数である。\n",
        "* 擬似乱数は、現在の状態をもとに、deterministicな計算によって生成される。\n",
        " * そして、次の乱数発生で使われる状態も、現在の状態からdeterministicに算出される。\n",
        "* 擬似乱数の生成は、全てdeterministicな計算によって進行するので、初期値であるシードが同じなら、必ず同じ乱数列が生成される。\n",
        "\n",
        "* JAXでは、擬似乱数を生成するたびに状態が次から次へと遷移するという、この擬似乱数生成の特徴が、関数を書く上で問題となる。\n",
        "* というのも、NumPyやPyTorchと同じように、関数の中で乱数を発生させると、関数の外側に影響を与えてしまうからである。\n",
        "* このように、外側に影響を与える関数は、JAXの考え方に馴染まない。\n",
        "* そこで、JAXでは、その中で乱数を使う関数に対して、明示的に擬似乱数の状態を渡すのが、コードを書く上での流儀となっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* まず、シード`42`に対するPRNG stateを、次のように作成する。"
      ],
      "metadata": {
        "id": "N241D8ZeGXBa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAAPGlxv1vWX"
      },
      "outputs": [],
      "source": [
        "key = jax.random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkcmlIb91vWX"
      },
      "source": [
        "* そして、このPRNG stateを乱数の生成に使う。\n",
        "* 以下のセルを実行し、JAXとNumPyの違いを確認しよう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7HDoKSO1vWX"
      },
      "outputs": [],
      "source": [
        "# A non-desirable way of generating pseudo-random numbers...\n",
        "jax_random_number_1 = jax.random.normal(key)\n",
        "jax_random_number_2 = jax.random.normal(key)\n",
        "print('JAX - Random number 1:', jax_random_number_1)\n",
        "print('JAX - Random number 2:', jax_random_number_2)\n",
        "\n",
        "# Typical random numbers in NumPy\n",
        "np.random.seed(42)\n",
        "np_random_number_1 = np.random.normal()\n",
        "np_random_number_2 = np.random.normal()\n",
        "print('NumPy - Random number 1:', np_random_number_1)\n",
        "print('NumPy - Random number 2:', np_random_number_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIosrUj01vWX"
      },
      "source": [
        "* NumPyのように乱数を発生させたいとき、JAXでは、PRNG stateを分岐(split)する。\n",
        "* そして、splitすることで得られたsubkeyを、乱数を発生させる関数に渡す。\n",
        " * 乱数のkeyのsplitには`jax.random.split(...)`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMxzsLz01vWX"
      },
      "outputs": [],
      "source": [
        "key, key_ = jax.random.split(key)\n",
        "jax_random_number_1 = jax.random.normal(key_)\n",
        "key, key_ = jax.random.split(key)\n",
        "jax_random_number_2 = jax.random.normal(key_)\n",
        "print('JAX new - Random number 1:', jax_random_number_1)\n",
        "print('JAX new - Random number 2:', jax_random_number_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD-Vt2wk1vWX"
      },
      "source": [
        "* 上のセルを繰り返し実行すると、その度に異なる乱数を得る。\n",
        "* このようにJAXでは、乱数を生成させる前に必ずPRNG keyをsplitする。\n",
        " * cf. JAX's tutorial on [Pseudo Random Numbers](https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpRFYeqm1vWY"
      },
      "source": [
        "### 自動微分\n",
        "* JAXでは自動微分が使える。\n",
        " * 自動微分について、PyTorchやTensorFlowを代替するライブラリとして利用できる。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 関数の例\n",
        "$$ y = \\frac{1}{N}\\sum_{i=1}^N\\left[\\left(x_i+2\\right)^2+3\\right]$$"
      ],
      "metadata": {
        "id": "BRnZYOQt20uL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkOjB8UX1vWY"
      },
      "outputs": [],
      "source": [
        "def simple_graph(x):\n",
        "    x = x + 2\n",
        "    x = x ** 2\n",
        "    x = x + 3\n",
        "    y = x.mean()\n",
        "    return y\n",
        "\n",
        "inp = jnp.arange(3, dtype=jnp.float32)\n",
        "print('Input', inp)\n",
        "print('Output', simple_graph(inp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DAjLr3w1vWY"
      },
      "source": [
        "* PyTorchでの計算グラフに相当するものは、JAXでは\n",
        "Jaxprと呼ばれる。\n",
        " * あえて訳すと「JAX表示式」？\n",
        " * cf. https://jax.readthedocs.io/en/latest/jaxpr.html\n",
        "* `jax.make_jaxpr`を使えば、関数のjaxprが得られる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfAjUKUj1vWY"
      },
      "outputs": [],
      "source": [
        "jax.make_jaxpr(simple_graph)(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 入力として与える配列の形を変えると、得られるjaxprも変わる。"
      ],
      "metadata": {
        "id": "xN2LYGemNnd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp2 = jnp.ones((3, 3), dtype=jnp.float32)\n",
        "jax.make_jaxpr(simple_graph)(inp2)"
      ],
      "metadata": {
        "id": "gnY1c4fVNa0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 自動微分には`jax.grad`を使う。\n",
        " * 自動微分は、関数をtransformして別の関数を得ること、とみなせる。"
      ],
      "metadata": {
        "id": "qe3NRb1bO5S5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4_1clqw1vWZ"
      },
      "outputs": [],
      "source": [
        "grad_function = jax.grad(simple_graph)\n",
        "gradients = grad_function(inp)\n",
        "print('Gradient', gradients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvVpl9HE1vWZ"
      },
      "source": [
        "* 勾配だけでなく、関数の出力値も得たいときは`jax.value_and_grad`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS__oi4h1vWZ"
      },
      "outputs": [],
      "source": [
        "val_grad_function = jax.value_and_grad(simple_graph)\n",
        "val_grad_function(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRtzeUgG1vWa"
      },
      "source": [
        "### Just-In-Timeコンパイラ\n",
        "\n",
        "* JAXには、関数をjust-in-timeでコンパイルする機能が備わっている。\n",
        " * コンパイルは、与えられた関数をより高速に実行できる関数へとtransformすること、とみなせる。\n",
        "* JITコンパイルには`jax.jit`を使う。\n",
        " * もしくは、関数の直前で`@jax.jit`というデコレータを用いる。\n",
        "* コンパイルされた関数は、XLAにより高速化される。\n",
        " * https://www.tensorflow.org/xla?hl=ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLByUDa01vWa"
      },
      "outputs": [],
      "source": [
        "jitted_function = jax.jit(simple_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* コンパイルするとどのくらい実行が高速化されるのか、調べる。"
      ],
      "metadata": {
        "id": "fEgun39HRqVE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV6OaLnD1vWa"
      },
      "outputs": [],
      "source": [
        "# Create a new random subkey for generating new random values\n",
        "key, key_ = jax.random.split(key)\n",
        "large_input = jax.random.normal(key_, (10000,))\n",
        "# Run the jitted function once to start compilation\n",
        "_ = jitted_function(large_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JAXは、デフォルトで非同期に計算を行う。\n",
        " * 計算結果を収める場所だけ先に作っておいて、計算され次第、そこに答えを埋めていく、という感じ。\n",
        "* そのため、計算の実行時間を測るときは`block_until_ready()`が必要。"
      ],
      "metadata": {
        "id": "Bn1rneom5B5k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH7eC9fF1vWa"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "simple_graph(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXK1NI1m1vWa"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "jitted_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 微分した結果得られた関数も、コンパイルできる。"
      ],
      "metadata": {
        "id": "1mBPM7Et5dUJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M67dePAe1vWa"
      },
      "outputs": [],
      "source": [
        "jitted_grad_function = jax.jit(grad_function)\n",
        "_ = jitted_grad_function(large_input)  # Apply once to compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRfbxTG61vWb"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "grad_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8ep9wMx1vWb"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "jitted_grad_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yrZo72D1vWb"
      },
      "source": [
        "## Flax\n",
        "* JAXだけ使っても、複雑なニューラルネットワークを実装することはできる。\n",
        "* しかし、非常に煩雑な作業になる。\n",
        "* そこで、深層学習むけのコードを書くときには、専用のライブラリを使う。\n",
        "\n",
        " * [Flax](https://flax.readthedocs.io/en/latest/index.html), started by the Google Brain Team, focuses on flexibility and clarity.\n",
        " * [Haiku](https://dm-haiku.readthedocs.io/en/latest/), from DeepMind, focuses on simplicity and compositionality.\n",
        " * [Trax](https://github.com/google/trax), maintained by the Google Brain Team, provides solutions for common training tasks\n",
        " * [Equinox](https://github.com/patrick-kidger/equinox), created by Patrick Kidger and Cristian Garcia, implements neural networks as callable PyTrees\n",
        " * [Jraph](https://github.com/deepmind/jraph), from DeepMind, is a graph neural network library (similar to PyTorch Geometric)\n",
        "\n",
        "* ここではFlaxを使う。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 以下のようなデータセットを二値分類するMLPのtrainingを、Flaxで書いてみる。\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/continuous_xor.svg?raw=1\" width=\"350px\"></center>"
      ],
      "metadata": {
        "id": "biuU3heT6EcJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_UpIXYn1vWb"
      },
      "source": [
        "### モデルの定義\n",
        "\n",
        "* パッケージ`flax.linen`を使うと便利。\n",
        " * https://flax.readthedocs.io/en/latest/flax.linen.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import flax\n",
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "U7PJSIu8R4oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqxUUkKt1vWb"
      },
      "source": [
        "#### Flaxの`nn.Module`\n",
        "\n",
        "* PyTorchの`nn.Module`と似ている。\n",
        "* 簡単なMLPの実装例を、下に示す。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUhvLog71vWc"
      },
      "source": [
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/small_neural_network.svg?raw=1\" width=\"300px\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwzOArTg1vWc"
      },
      "outputs": [],
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "    num_hidden : int   # Number of hidden neurons\n",
        "    num_outputs : int  # Number of output neurons\n",
        "\n",
        "    def setup(self):\n",
        "        # Create the modules we need to build the network\n",
        "        # nn.Dense is a linear layer\n",
        "        self.linear1 = nn.Dense(features=self.num_hidden)\n",
        "        self.linear2 = nn.Dense(features=self.num_outputs)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.linear1(x)\n",
        "        x = nn.tanh(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-dN48er1vWc"
      },
      "outputs": [],
      "source": [
        "model = SimpleClassifier(num_hidden=8, num_outputs=1)\n",
        "# Printing the model shows its attributes\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* モデルそのものと、モデル・パラメータの値の特定の設定とは、別々に扱う。"
      ],
      "metadata": {
        "id": "eiFIPt8-WTjr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjEqaM771vWc"
      },
      "outputs": [],
      "source": [
        "key, key_ = jax.random.split(key)\n",
        "inp = jax.random.normal(key_, (8, 2))  # Batch size 8, input size 2\n",
        "# Initialize the model\n",
        "key, key_ = jax.random.split(key)\n",
        "params = model.init(key_, inp)\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd4-Gs8g1vWc"
      },
      "source": [
        "* 特定の入力に対する出力を得るときは、モデルパラメータの値の特定の設定も、同時に指定する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrAK7HBW1vWd"
      },
      "outputs": [],
      "source": [
        "model.apply(params, inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4xSnO8i1vWd"
      },
      "source": [
        "### データの準備\n",
        "* データを扱うためのコードだけPyTorchで書くことができる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cE3_sU71vWd"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データセット"
      ],
      "metadata": {
        "id": "b6iqhZumZLy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EExjIqXM1vWd"
      },
      "outputs": [],
      "source": [
        "class XORDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, size, seed, std=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            size - Number of data points we want to generate\n",
        "            seed - The seed to use to create the PRNG state with which we want to generate the data points\n",
        "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.np_rng = np.random.RandomState(seed=seed)\n",
        "        self.std = std\n",
        "        self.generate_continuous_xor()\n",
        "\n",
        "    def generate_continuous_xor(self):\n",
        "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
        "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
        "        # If x=y, the label is 0.\n",
        "        data = self.np_rng.randint(low=0, high=2, size=(self.size, 2)).astype(np.float32)\n",
        "        label = (data.sum(axis=1) == 1).astype(np.int32)\n",
        "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
        "        data += self.np_rng.normal(loc=0.0, scale=self.std, size=data.shape)\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return the idx-th data point of the dataset\n",
        "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
        "        data_point = self.data[idx]\n",
        "        data_label = self.label[idx]\n",
        "        return data_point, data_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUMwoG8X1vWd"
      },
      "outputs": [],
      "source": [
        "dataset = XORDataset(size=200, seed=42)\n",
        "print(\"Size of dataset:\", len(dataset))\n",
        "print(\"Data point 0:\", dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5EEm1d_1vWe"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(data, label):\n",
        "    data_0 = data[label == 0]\n",
        "    data_1 = data[label == 1]\n",
        "    \n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "    plt.title(\"Dataset samples\")\n",
        "    plt.ylabel(r\"$x_2$\")\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ywMvJQI1vWe"
      },
      "outputs": [],
      "source": [
        "visualize_samples(dataset.data, dataset.label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUyINWEq1vWe"
      },
      "source": [
        "#### データローダ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtohgO-a1vWe"
      },
      "outputs": [],
      "source": [
        "# This collate function is taken from the JAX tutorial with PyTorch Data Loading\n",
        "# https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html\n",
        "def numpy_collate(batch):\n",
        "    if isinstance(batch[0], np.ndarray):\n",
        "        return np.stack(batch)\n",
        "    elif isinstance(batch[0], (tuple,list)):\n",
        "        transposed = zip(*batch)\n",
        "        return [numpy_collate(samples) for samples in transposed]\n",
        "    else:\n",
        "        return np.array(batch)\n",
        "\n",
        "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=numpy_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyvqCdJ11vWe"
      },
      "outputs": [],
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(data_loader))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the \n",
        "# dimensions of the data point returned from the dataset class\n",
        "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LKzDUzK1vWe"
      },
      "source": [
        "### 最適化アルゴリズム\n",
        "* `optax`というライブラリを使う。\n",
        " * https://optax.readthedocs.io/en/latest/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optax"
      ],
      "metadata": {
        "id": "A-WRNNc2Ubjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_urrBzR1vWe"
      },
      "outputs": [],
      "source": [
        "# Input to the optimizer are optimizer settings like learning rate\n",
        "optimizer = optax.sgd(learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 訓練の状態を初期化する。"
      ],
      "metadata": {
        "id": "qpermNTQXLM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6_3rLb-1vWf"
      },
      "outputs": [],
      "source": [
        "from flax.training import train_state\n",
        "\n",
        "model_state = train_state.TrainState.create(apply_fn=model.apply,\n",
        "                                            params=params,\n",
        "                                            tx=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jsIXSyo1vWf"
      },
      "source": [
        "### 損失関数\n",
        "\n",
        "* 二値分類なので、クロスエントロピーを損失関数として使う。\n",
        "\n",
        "$$\\mathcal{L}_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$$\n",
        "\n",
        "where $y$ are our labels, and $x$ our predictions, both in the range of $[0,1]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIkQbBbY1vWf"
      },
      "outputs": [],
      "source": [
        "def calculate_loss_acc(state, params, batch):\n",
        "    data_input, labels = batch\n",
        "    # Obtain the logits and predictions of the model for the input data\n",
        "    logits = state.apply_fn(params, data_input).squeeze(axis=-1)\n",
        "    pred_labels = (logits > 0).astype(jnp.float32)\n",
        "    # Calculate the loss and accuracy\n",
        "    loss = optax.sigmoid_binary_cross_entropy(logits, labels).mean()\n",
        "    acc = (pred_labels == labels).mean()\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhmWPv_J1vWf"
      },
      "source": [
        "* 試しに損失を計算させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lr8WpPU1vWf"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(data_loader))\n",
        "calculate_loss_acc(model_state, model_state.params, batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CsrYdsZ1vWf"
      },
      "source": [
        "### JITコンパイルによる高速化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gYvScaY1vWf"
      },
      "outputs": [],
      "source": [
        "@jax.jit  # Jit the function for efficiency\n",
        "def train_step(state, batch):\n",
        "    # Gradient function\n",
        "    grad_fn = jax.value_and_grad(calculate_loss_acc,  # Function to calculate the loss\n",
        "                                 argnums=1,  # Parameters are second argument of the function\n",
        "                                 has_aux=True  # Function has additional outputs, here accuracy\n",
        "                                )\n",
        "    # Determine gradients for current model, parameters and batch\n",
        "    (loss, acc), grads = grad_fn(state, state.params, batch)\n",
        "    # Perform parameter update with gradients and optimizer\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    # Return state and any other value we might want\n",
        "    return state, loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgkbNuYS1vWf"
      },
      "outputs": [],
      "source": [
        "@jax.jit  # Jit the function for efficiency\n",
        "def eval_step(state, batch):\n",
        "    # Determine the accuracy\n",
        "    _, acc = calculate_loss_acc(state, state.params, batch)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQLz0jj21vWg"
      },
      "source": [
        "### 訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4hH-jCF1vWg"
      },
      "outputs": [],
      "source": [
        "train_dataset = XORDataset(size=2500, seed=42)\n",
        "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=numpy_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3YwR_tz1vWg"
      },
      "outputs": [],
      "source": [
        "def train_model(state, data_loader, num_epochs=100):\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        for batch in data_loader:\n",
        "            state, loss, acc = train_step(state, batch)\n",
        "            # We could use the loss and accuracy for logging here, e.g. in TensorBoard\n",
        "            # For simplicity, we skip this part here\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_NlI7Ht1vWg"
      },
      "outputs": [],
      "source": [
        "trained_model_state = train_model(model_state, train_data_loader, num_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9SDoUz51vWg"
      },
      "source": [
        "#### モデルの保存\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTivdS6X1vWg"
      },
      "outputs": [],
      "source": [
        "from flax.training import checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtM23Wu71vWg"
      },
      "source": [
        "* ここでは、パラメータだけではなく、モデルの状態全体を保存する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8eV6pRj1vWg"
      },
      "outputs": [],
      "source": [
        "checkpoints.save_checkpoint(ckpt_dir='my_checkpoints/',  # Folder to save checkpoint in\n",
        "                            target=trained_model_state,  # What to save. To only save parameters, use model_state.params\n",
        "                            step=100,  # Training step or other metric to save best model on\n",
        "                            prefix='my_model',  # Checkpoint file name prefix\n",
        "                            overwrite=True   # Overwrite existing checkpoint files\n",
        "                           )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOTjT1fp1vWg"
      },
      "source": [
        "* 読み込みは以下のようにすればよい。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2olUMhn1vWh"
      },
      "outputs": [],
      "source": [
        "loaded_model_state = checkpoints.restore_checkpoint(\n",
        "                                             ckpt_dir='my_checkpoints/',   # Folder with the checkpoints\n",
        "                                             target=model_state,   # (optional) matching object to rebuild state in\n",
        "                                             prefix='my_model'  # Checkpoint file name prefix\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5de2gOPL1vWh"
      },
      "source": [
        "* `loaded_model_state`と`trained_model_state`は、完全に同じパラメータ値を持っているはず。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6__XcHZ1vWh"
      },
      "source": [
        "### 評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYDWg9-Z1vWh"
      },
      "outputs": [],
      "source": [
        "test_dataset = XORDataset(size=500, seed=123)\n",
        "# drop_last -> Don't drop the last batch although it is smaller than 128\n",
        "test_data_loader = data.DataLoader(test_dataset, \n",
        "                                   batch_size=128, \n",
        "                                   shuffle=False, \n",
        "                                   drop_last=False, \n",
        "                                   collate_fn=numpy_collate) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIeS-gOc1vWh"
      },
      "outputs": [],
      "source": [
        "def eval_model(state, data_loader):\n",
        "    all_accs, batch_sizes = [], []\n",
        "    for batch in data_loader:\n",
        "        batch_acc = eval_step(state, batch)\n",
        "        all_accs.append(batch_acc)\n",
        "        batch_sizes.append(batch[0].shape[0])\n",
        "    # Weighted average since some batches might be smaller\n",
        "    acc = sum([a*b for a,b in zip(all_accs, batch_sizes)]) / sum(batch_sizes)\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGmqHiCc1vWh"
      },
      "outputs": [],
      "source": [
        "eval_model(trained_model_state, test_data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcABoIuh1vWh"
      },
      "source": [
        "#### モデルパラメータのバインディング\n",
        "* 今まで、モデルそのものと、モデルパラメータの値の特定の設定とを、別々に管理してきた。\n",
        "* しかし、これでは不便。\n",
        "* 以下のようにすれば、モデルのインスタンスを、特定のパラメータ値の設定へとbindできる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqLyODhJ1vWh"
      },
      "outputs": [],
      "source": [
        "trained_model = model.bind(trained_model_state.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgBBj0RS1vWh"
      },
      "outputs": [],
      "source": [
        "data_input, labels = next(iter(data_loader))\n",
        "out = trained_model(data_input)  # No explicit parameter passing necessary anymore\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73of2WWl1vWi"
      },
      "source": [
        "* このほうが、PyTorchっぽい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhWu7C8t1vWi"
      },
      "source": [
        "#### 分類境界の可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "rx-1dTe81vWi"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import to_rgba\n",
        "\n",
        "def visualize_classification(model, data, label):\n",
        "    data_0 = data[label == 0]\n",
        "    data_1 = data[label == 1]\n",
        "    \n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "    plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "    plt.title(\"Dataset samples\")\n",
        "    plt.ylabel(r\"$x_2$\")\n",
        "    plt.xlabel(r\"$x_1$\")\n",
        "    plt.legend()\n",
        "    \n",
        "    # Let's make use of a lot of operations we have learned above\n",
        "    c0 = np.array(to_rgba(\"C0\"))\n",
        "    c1 = np.array(to_rgba(\"C1\"))\n",
        "    x1 = jnp.arange(-0.5, 1.5, step=0.01)\n",
        "    x2 = jnp.arange(-0.5, 1.5, step=0.01)\n",
        "    xx1, xx2 = jnp.meshgrid(x1, x2, indexing='ij')  # Meshgrid function as in numpy\n",
        "    model_inputs = np.stack([xx1, xx2], axis=-1)\n",
        "    logits = model(model_inputs)\n",
        "    preds = nn.sigmoid(logits)\n",
        "    output_image = (1 - preds) * c0[None,None] + preds * c1[None,None]  # Specifying \"None\" in a dimension creates a new one\n",
        "    output_image = jax.device_get(output_image)  # Convert to numpy array. This only works for tensors on CPU, hence first push to CPU\n",
        "    plt.imshow(output_image, origin='lower', extent=(-0.5, 1.5, -0.5, 1.5))\n",
        "    plt.grid(False)\n",
        "    return fig\n",
        "\n",
        "_ = visualize_classification(trained_model, dataset.data, dataset.label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VIGTMNdV8JeN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}